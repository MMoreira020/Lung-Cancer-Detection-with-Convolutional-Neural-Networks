# Lung-Cancer-Detection-with-Convolutional-Neural-Networks
AnÃ¡lise comparativa de 5 arquiteturas de Redes Neurais (ResNet, DenseNet, Inception, SqueezeNet, EfficientNet) treinadas com otimizadores ADAM e SGD. Este projeto visa demonstrar o impacto da escolha do otimizador na acurÃ¡cia e na velocidade de treinamento dos modelos.

## ğŸ§  Modelos

As seguintes arquiteturas de redes neurais foram implementadas e treinadas:

* **ResNet-50:** Uma rede neural convolucional de 50 camadas que introduz o conceito de "conexÃµes residuais" (skip connections) para mitigar o problema do gradiente descendente e permitir o treinamento de redes muito profundas.

* **DenseNet-121:** Caracteriza-se por sua conectividade densa, onde cada camada recebe as saÃ­das de todas as camadas anteriores. Isso promove a reutilizaÃ§Ã£o de caracterÃ­sticas, melhora o fluxo de gradiente e reduz o nÃºmero de parÃ¢metros.

* **InceptionV3:** Desenvolvida pelo Google, esta arquitetura utiliza "mÃ³dulos Inception" que aplicam convoluÃ§Ãµes de diferentes tamanhos em paralelo, permitindo a captura de caracterÃ­sticas em mÃºltiplas escalas de forma computacionalmente eficiente.

* **SqueezeNet 1.0:** Uma arquitetura leve e eficiente, projetada para ter um nÃºmero significativamente menor de parÃ¢metros em comparaÃ§Ã£o com outras redes, sem comprometer a acurÃ¡cia. Ã‰ ideal para aplicaÃ§Ãµes em dispositivos com recursos limitados.

* **EfficientNetB2:** Parte de uma famÃ­lia de modelos que foram escalonados de forma otimizada em termos de profundidade, largura e resoluÃ§Ã£o da rede atravÃ©s de um coeficiente composto. O EfficientNetB2 oferece um excelente equilÃ­brio entre acurÃ¡cia e eficiÃªncia computacional.

## âš™ï¸ Otimizadores

Cada um dos modelos acima foi treinado utilizando os dois otimizadores a seguir:

* **ADAM (Adaptive Moment Estimation):** Um otimizador popular que calcula taxas de aprendizado adaptativas para cada parÃ¢metro. Ele combina as vantagens de dois outros algoritmos, Momentum e RMSprop, e Ã© conhecido por sua rÃ¡pida convergÃªncia.

* **SGD (Stochastic Gradient Descent):** Um otimizador clÃ¡ssico e fundamental. A versÃ£o utilizada neste projeto provavelmente inclui aprimoramentos comuns como momentum e decaimento da taxa de aprendizado, que ajudam a acelerar o treinamento e a evitar mÃ­nimos locais.

## ğŸ“‚ Estrutura do RepositÃ³rio

â”œâ”€â”€ DenseNet-121/
â”‚   â”œâ”€â”€ Bruto/
â”‚   â”‚   â”œâ”€â”€ DenseNet-121_ADAM.py
â”‚   â”‚   â””â”€â”€ DenseNet-121_SGD.py
â”‚   â””â”€â”€ Filtro_de_Wavelet/
â”‚       â”œâ”€â”€ DenseNet-121_ADAM.py
â”‚       â””â”€â”€ DenseNet-121_SGD.py
â”œâ”€â”€ EfficientNetB2/
â”‚   â”œâ”€â”€ Bruto/
â”‚   â”‚   â”œâ”€â”€ EfficientNetB2_ADAM.py
â”‚   â”‚   â””â”€â”€ EfficientNetB2_SGD.py
â”‚   â””â”€â”€ Filtro_de_Wavelet/
â”‚       â”œâ”€â”€ EfficientNetB2_ADAM.py
â”‚       â””â”€â”€ EfficientNetB2_SGD.py
â”œâ”€â”€ InceptionV3/
â”‚   â”œâ”€â”€ Bruto/
â”‚   â”‚   â”œâ”€â”€ InceptionV3_ADAM.py
â”‚   â”‚   â””â”€â”€ InceptionV3_SGD.py
â”‚   â””â”€â”€ Filtro_de_Wavelet/
â”‚       â”œâ”€â”€ InceptionV3_ADAM.py
â”‚       â””â”€â”€ InceptionV3_SGD.py
â”œâ”€â”€ ResNet-50/
â”‚   â”œâ”€â”€ Bruto/
â”‚   â”‚   â”œâ”€â”€ ResNet-50_ADAM.py
â”‚   â”‚   â””â”€â”€ ResNet-50_SGD.py
â”‚   â””â”€â”€ Filtro_de_Wavelet/
â”‚       â”œâ”€â”€ ResNet-50_ADAM.py
â”‚       â””â”€â”€ ResNet-50_SGD.py
â”œâ”€â”€ SqueezeNet1_0/
â”‚   â”œâ”€â”€ Bruto/
â”‚   â”‚   â”œâ”€â”€ SqueezeNet1_0_ADAM.py
â”‚   â”‚   â””â”€â”€ SqueezeNet1_0_SGD.py
â”‚   â””â”€â”€ Filtro_de_Wavelet/
â”‚       â”œâ”€â”€ SqueezeNet1_0_ADAM.py
â”‚       â””â”€â”€ SqueezeNet1_0_SGD.py
â””â”€â”€ README.md

## ğŸš€ Como Utilizar

Para executar os scripts de treinamento, vocÃª precisarÃ¡ ter as seguintes bibliotecas instaladas:

* Python 3.x
* PyTorch
* NumPy
* Matplotlib (para visualizaÃ§Ã£o dos resultados)

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/seu-usuario/Lung-Cancer-Detection-with-Convolutional-Neural-Networks.git
    ```

2.  **Navegue atÃ© a pasta do modelo desejado:**
    ```bash
    # Exemplo para treinar ResNet-50 com dados brutos e otimizador ADAM
    cd Lung-Cancer-Detection-with-Convolutional-Neural-Networks/ResNet-50/Bruto

    # Exemplo para treinar ResNet-50 com dados filtrados (Wavelet) e otimizador SGD
    cd Lung-Cancer-Detection-with-Convolutional-Neural-Networks/ResNet-50/Filtro_de_Wavelet
    ```

3.  **Execute o script de treinamento:**
    ```bash
    # Exemplo para o primeiro caso (ResNet-50, Bruto, ADAM)
    python ResNet-50_ADAM.py

    # Exemplo para o segundo caso (ResNet-50, Filtro_de_Wavelet, SGD)
    python ResNet-50_SGD.py
    ```

## ğŸ“ˆ Resultados (Exemplo)

*(Esta seÃ§Ã£o apresenta um resumo comparativo da acurÃ¡cia de validaÃ§Ã£o para cada arquitetura, utilizando os dados do conjunto de teste original.)*

| Modelo          | Otimizador | AcurÃ¡cia de ValidaÃ§Ã£o |
| :-------------- | :--------- | :-------------------- |
| ResNet-50       | ADAM       | 92.78%                |
| ResNet-50       | SGD        | 91.72%                |
| DenseNet-121    | ADAM       | 90.00%                |
| DenseNet-121    | SGD        | 91.10%                |
| EfficientNet-B2 | ADAM       | 88.67%                |
| EfficientNet-B2 | SGD        | 90.41%                |
| Inception.V3    | ADAM       | 86.62%                |
| Inception.V3    | SGD        | 81.82%                |
| Squeezenet1.0   | ADAM       | 90.41%                |
| Squeezenet1.0   | SGD        | 86.56%                |

*(Esta seÃ§Ã£o apresenta um resumo comparativo da acurÃ¡cia de validaÃ§Ã£o para cada arquitetura, utilizando os dados do conjunto de teste processado com Wavelet.)*

| Modelo          | Otimizador | AcurÃ¡cia de ValidaÃ§Ã£o |
| :-------------- | :--------- | :-------------------- |
| ResNet-50       | ADAM       | 90.41%                |
| ResNet-50       | SGD        | 91.10%                |
| DenseNet-121    | ADAM       | 90.41%                |
| DenseNet-121    | SGD        | 90.73%                |
| EfficientNet-B2 | ADAM       | 86.30%                |
| EfficientNet-B2 | SGD        | 91.10%                |
| Inception.V3    | ADAM       | 83.30%                |
| Inception.V3    | SGD        | 85.93%                |
| Squeezenet1.0   | ADAM       | 90.56%                |
| Squeezenet1.0   | SGD        | 91.10%                |


## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª tiver sugestÃµes para melhorar este projeto, sinta-se Ã  vontade para abrir uma "issue" ou enviar um "pull request".
